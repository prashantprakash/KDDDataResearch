Ubuntu and other Debian-based distributions

echo "deb https://dl.bintray.com/sbt/debian /" | sudo tee -a /etc/apt/sources.list.d/sbt.list
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823
sudo apt-get update
sudo apt-get install sbt


for using MLLIB 

in dependency we have to write 

libraryDependencies += "org.apache.spark" % "spark-mllib_2.10" % "1.1.0" % "provided"


./spark-submit --class "Kmeans" --master local[4] Kmeans/target/scala-2.10/kmeans_2.10-1.0.jar

./spark-submit --class "Gaussian" --master local[4] Gaussian/target/scala-2.10/gaussian_2.10-1.0.jar

--driver-memory 4G //if you face any error regarding rdd memory error

./spark-submit --class "Kmeans" --master local[4] --driver-memory 12G Kmeans/target/scala-2.10/kmeans_2.10-1.0.jar

// running DataInfo scala to get information about data
./spark-submit --class "Datainfo" --master local[4] --driver-memory 12G datainfo/target/scala-2.10/datainfo_2.10-1.0.jar

// running Kmeans under KmeanExp 

./spark-submit --class "Kmeans" --master local[4] --driver-memory 12G KmeansExp/target/scala-2.10/kmeans_2.10-1.0.jar

// running Kmeans under Kmeans Normalize 

./spark-submit --class "Kmeans" --master local[4] --driver-memory 12G KmeansNormalize/target/scala-2.10/kmeans_2.10-1.0.jar  > KmeansNormalizeOutput

// running TrainTest

./spark-submit --class "Kmeans" --master local[4] --driver-memory 12G KmeansTrainTest/target/scala-2.10/kmeans_2.10-1.0.jar 

// running PCA

./spark-submit --class "PCA" --master local[4] --driver-memory 12G PCA/target/scala-2.10/pca_2.10-1.0.jar


// running PCA for train and test

./spark-submit --class "PCA" --master local[4] --driver-memory 12G PCATrainTest/target/scala-2.10/pca_2.10-1.0.jar

// running PCA Anomaly 

./spark-submit --class "PCA" --master local[4] --driver-memory 12G PCANormal/target/scala-2.10/pca_2.10-1.0.jar 10 10 70000 


./spark-submit --class "Clusterscore" --master local[4] --driver-memory 12G clusterscore/target/scala-2.10/clusterscore_2.10-1.0.jar
